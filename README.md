# TB-Data-Analysis

<div align="center">
<h1 align="center">
<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT46xYN2VAk3ZgHs4MYvAWy-PkBfUBwG9XzO_YaJYE&s" width="100" /> 
<br>TB-Data-Analysis</h1>
<h3>◦ Developed with the software and tools below.</h3>

<p align="center">
<img src="https://img.shields.io/badge/Python-3776AB.svg?style&logo=Python&logoColor=white" alt="Python" />

<img src="https://img.shields.io/badge/pandas-150458.svg?style&logo=pandas&logoColor=white" alt="pandas" />
<img src="https://img.shields.io/badge/NumPy-013243.svg?style&logo=NumPy&logoColor=white" alt="NumPy" />
<img src="https://img.shields.io/badge/Markdown-000000.svg?style&logo=Markdown&logoColor=white" alt="Markdown" />
</p>
<img src="https://img.shields.io/github/license/yasminfarhan/TB-Data-Analysis?style&color=5D6D7E" alt="GitHub license" />
<img src="https://img.shields.io/github/last-commit/yasminfarhan/TB-Data-Analysis?style&color=5D6D7E" alt="git-last-commit" />
<img src="https://img.shields.io/github/commit-activity/m/yasminfarhan/TB-Data-Analysis?style&color=5D6D7E" alt="GitHub commit activity" />
<img src="https://img.shields.io/github/languages/top/yasminfarhan/TB-Data-Analysis?style&color=5D6D7E" alt="GitHub top language" />
</div>

---

## 📖 Table of Contents
- [📖 Table of Contents](#-table-of-contents)
- [📍 Overview](#-overview)
- [📂 Repository Structure](#-repository-structure)
- [⚙️ Modules](#modules)
- [🚀 Getting Started](#-getting-started)
    - [🔧 Installation](#-installation)
    - [🤖 Running TB-Data-Analysis](#-running-TB-Data-Analysis)
    - [🧪 Tests](#-tests)
- [👏 Acknowledgments](#-acknowledgments)

---


## 📍 Overview

This repository was developed to facilitate the preprocessing of experiment data downloaded from Gorilla, a Javascript based experiment hosting platform. The experiment consists of a four task cognitive battery, developed in collaboration with the Iigaya Lab, at New York State Psychiatric Institute, affiliated with Columbia University Medical Center, under the supervision of Private Investigator Dr. Kiyohito Iigaya. 

---


## 📂 Repository Structure

```sh
└── TB-Data-Analysis/
    ├── README.md
    ├── data/
    │   ├── cleaned_data/
    │   └── raw_data/
    └── scripts/
        ├── requirements.txt
        ├── tb_a_cleanup.py
        ├── tb_analysis.py
        ├── tb_b_cleanup.py
        ├── tb_c_cleanup.py
        ├── tb_d_cleanup.py
        ├── tb_gen_task_params.py
        ├── tb_q_processing.py
        └── utils.py
```


---

## ⚙️ Modules

<details closed><summary>Scripts</summary>

| File                                                                                                              | Summary                   |
| ---                                                                                                               | ---                       |
| [tb_q_processing.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_q_processing.py)       | This script computes questionnaire scores by converting raw scores and taking into consideration reverse scoring as specified by the questionnaire map. |
| [tb_a_cleanup.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_a_cleanup.py)             | This script processes raw data from the "3 Arm Bandit" task, specifically versions Av1 - NoWin/Loss and Av3 - Win/NoLoss. |
| [tb_b_cleanup.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_b_cleanup.py)             | This script processes raw data from the "Information Seeking" task, specifically versions 1, 2, and 3. |
| [tb_c_cleanup.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_c_cleanup.py)             | This script processes raw data from the "Delay Match to Sample" experiment. |
| [tb_d_cleanup.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_d_cleanup.py)             | This script processes raw data from the "N-Back / Effort discounting" task. |
| [tb_gen_task_params.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_gen_task_params.py) | This script generates task parameters from the cleaned up trial by trial csv files generated by the *_cleanup.py scripts. |
| [utils.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/utils.py)                           | This file contains useful functions for use throughout the github repo. |
| [tb_analysis.py](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/tb_analysis.py)               | This is a skeleton .py file to allow for easy preliminary analysis of cleaned up task csv files generated by other scripts. |
| [requirements.txt](https://github.com/yasminfarhan/TB-Data-Analysis/blob/main/scripts/requirements.txt)           | Package requirements txt file. |


</details>

---

## 🚀 Getting Started

***Dependencies***

Please ensure you have the following dependencies installed on your system:

`- ℹ️ To be completed.`

### 🔧 Installation

1. Clone the TB-Data-Analysis repository:
```sh
git clone https://github.com/yasminfarhan/TB-Data-Analysis
```

2. Change to the project directory:
```sh
cd TB-Data-Analysis
```

3. Install the dependencies:
```sh
pip install -r requirements.txt
```

### 🤖 Running TB-Data-Analysis

Prior to running any cleanup scripts, ensure that you have downloaded the raw experiment data from Gorilla and manually organized the files into the HC (Healthy Control) and PT (Patient) directories. Additionally ensure that only data you wish to have preprocessed is included in the raw_data directory as the scripts in their current state will not distinguish between outdated and up to date experiment files.

Cleaned up csv files will be generated and saved into the relevant cleaned_data/PT or cleaned_data/HC directory, according to the command line argument specifed. 

#### Running Scripts

All scripts can be run in nearly the same way. For example, to run tb_a_cleanup.py, you would run:

```sh
python tb_a_cleanup.py [DIRECTORY]
```

where [DIRECTORY] is either HC or PT. The only exception to this is tb_b_cleanup.py, which requires the additional command line argument [EXPERIMENT_V], which can be either 1,2, or 3. 

The expected order of running these scripts would be that, following the saving of experiment data to their respective folders in raw_data, you would run tb_[TASK_V]_cleanup.py for tasks A-D, as well as tb_q_processing.py to generate the cleaned up experiment csv files, followed by tb_gen_task_params.py to generate the task features from those csv files for ease of further analysis. 

## 👏 Acknowledgments

`- ℹ️ Thank you to Drs Kiyohito Iigaya and Pradyumna Sepulveda for their guidance.`

[↑ Return](#Top)

---
